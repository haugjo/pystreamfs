{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDD Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from streamfs import streamfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_data = pd.read_csv('./datasets/credit.csv')\n",
    "credit_feature_names = np.array(credit_data.drop('Risk', 1).columns)\n",
    "credit_data = np.array(credit_data)\n",
    "\n",
    "har_data = pd.read_csv('./datasets/har_binary.csv')\n",
    "har_feature_names = np.array(har_data.drop('walking', 1).columns)\n",
    "har_data = np.array(har_data)\n",
    "\n",
    "usenet_data = pd.read_csv('./datasets/usenet.csv')\n",
    "usenet_feature_names = np.array(usenet_data.drop('target', 1).columns)\n",
    "usenet_data = np.array(usenet_data)\n",
    "\n",
    "kdd_data = pd.read_csv('./datasets/kddcup.csv')\n",
    "kdd_feature_names = np.array(kdd_data.drop('target', 1).columns)\n",
    "kdd_data = np.array(kdd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape Credit Data: {}\".format(credit_data.shape))\n",
    "print(\"Shape HAR: {}\".format(har_data.shape))\n",
    "print(\"Shape Usenet Data: {}\".format(usenet_data.shape))\n",
    "print(\"Shape KDD Data: {}\".format(kdd_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export target\n",
    "credit_X, credit_Y = streamfs.prepare_data(credit_data, 0, False)\n",
    "har_X, har_Y = streamfs.prepare_data(har_data, 0, False)\n",
    "usenet_X, usenet_Y = streamfs.prepare_data(usenet_data, 0, False)\n",
    "kdd_X, kdd_Y = streamfs.prepare_data(kdd_data, 0, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = dict()\n",
    "\n",
    "har = dict()\n",
    "har['X'] = har_X\n",
    "har['Y'] = har_Y\n",
    "\n",
    "credit = dict()\n",
    "credit['X'] = credit_X\n",
    "credit['Y'] = credit_Y\n",
    "\n",
    "usenet = dict()\n",
    "usenet['X'] = usenet_X\n",
    "usenet['Y'] = usenet_Y\n",
    "\n",
    "kdd = dict()\n",
    "kdd['X'] = kdd_X\n",
    "kdd['Y'] = kdd_Y\n",
    "\n",
    "datasets['har'] = har\n",
    "datasets['credit']= credit\n",
    "datasets['usenet']= usenet\n",
    "# datasets['kdd']= kdd -> is too big, but does drawing a sample make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run FS algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OFS\n",
    "Only binary classification -> Credit Score Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = dict()\n",
    "param['algorithm'] = 'svm'  # apply SVM classifier to calculate accuracy per time t\n",
    "\n",
    "ofs_results = dict()\n",
    "\n",
    "# for different data sets\n",
    "for name, data in datasets.items():\n",
    "    X = data['X'].copy()\n",
    "    Y = data['Y'].copy()\n",
    "\n",
    "    Y[Y == 0] = -1  # change 0 to -1, required by ofs\n",
    "\n",
    "    print(name)\n",
    "\n",
    "    # different number of features\n",
    "    for n in [5, 10, 20]:\n",
    "        param['num_features'] = n    \n",
    "\n",
    "        # different batch sizes\n",
    "        for b in [50, 100, 200]:\n",
    "            param['batch_size'] = b\n",
    "\n",
    "            print(param)\n",
    "\n",
    "            _, stats = streamfs.simulate_stream(X, Y, 'ofs', param)\n",
    "\n",
    "            ofs_results[\"{};{}F;{}B\".format(name,n,b)] = {k: stats[k] for k in ['acc_avg', 'time_avg', 'memory_avg', 'fscr_avg', 'acc_measures', 'features', 'fscr_measures']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./experiment_results/ofs_results.json', 'w') as fp:\n",
    "    json.dump(ofs_results, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FSDS\n",
    "Designed for unsupervised learning, can also handle multilabel problems -> Credit score and HAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = dict()\n",
    "param['b'] = []  # initial sketch matrix\n",
    "param['ell'] = 0  # initial sketch size\n",
    "param['algorithm'] = 'svm'  # apply SVM classifier to calculate accuracy per time t\n",
    "\n",
    "\n",
    "fsds_results = dict()\n",
    "\n",
    "# for different data sets\n",
    "for name, data in datasets.items():\n",
    "    X = data['X'].copy()\n",
    "    Y = data['Y'].copy()\n",
    "\n",
    "    param['k'] = len(np.unique(Y))  # no. of singular values (can be equal to no. of classes)\n",
    "\n",
    "    print(name)\n",
    "\n",
    "    # different number of features\n",
    "    for n in [5, 10, 20]:\n",
    "        param['num_features'] = n\n",
    "\n",
    "        # different batch sizes -> batch size for one iteration, must be at least the same size than k!!\n",
    "        for b in [50, 100, 200]:        \n",
    "            param['batch_size'] = b\n",
    "\n",
    "            # reset parameters\n",
    "            param['b'] = []  # initial sketch matrix\n",
    "            param['ell'] = 0  # initial sketch size\n",
    "\n",
    "            print(param)\n",
    "\n",
    "            w, stats = streamfs.simulate_stream(X, Y, 'fsds', param)\n",
    "\n",
    "            fsds_results[\"{};{}F;{}B\".format(name,n,b)] = {k: stats[k] for k in ['acc_avg', 'time_avg', 'memory_avg', 'fscr_avg', 'acc_measures', 'features', 'fscr_measures']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./experiment_results/fsds_results.json', 'w') as fp:\n",
    "    json.dump(fsds_results, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCNN\n",
    "Is extremely slow for HAR dataset -> thus only Credit score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = dict()\n",
    "param['algorithm'] = 'svm'  # apply SVM classifier to calculate accuracy per time t\n",
    "\n",
    "# Original parameters from paper\n",
    "param['max_n'] = 100  # maximum number of saved instances per cluster\n",
    "param['e_threshold'] = 3  # error threshold for splitting of a cluster\n",
    "\n",
    "# Additional parameters\n",
    "param['max_out_of_var_bound'] = 0.5 # percentage of variables that can at most be outside of variance boundary before new cluster is created\n",
    "param['p_diff_threshold'] = 50  # threshold of perc. diff. for split/death rate when drift is assumed (_detect_drift())\n",
    "\n",
    "mcnn_results = dict()\n",
    "\n",
    "# for different data sets\n",
    "for name, data in datasets.items():\n",
    "    X = data['X'].copy()\n",
    "    Y = data['Y'].copy()\n",
    "\n",
    "    print(name)\n",
    "\n",
    "    # different number of features\n",
    "    for n in [5, 10, 20]:\n",
    "        param['num_features'] = n\n",
    "\n",
    "        # different batch sizes -> batch size for one iteration, must be at least the same size than k!!\n",
    "        for b in [50, 100, 200]:        \n",
    "            param['batch_size'] = b\n",
    "\n",
    "            print(param)\n",
    "\n",
    "            w, stats = streamfs.simulate_stream(X, Y, 'mcnn', param)\n",
    "\n",
    "            mcnn_results[\"{};{}F;{}B\".format(name,n,b)] = {k: stats[k] for k in ['acc_avg', 'time_avg', 'memory_avg', 'fscr_avg', 'acc_measures', 'features', 'fscr_measures']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./experiment_results/mcnn_results.json', 'w') as fp:\n",
    "    json.dump(mcnn_results, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CancelOut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = dict()\n",
    "param['algorithm'] = 'svm'  # apply SVM classifier to calculate accuracy per time t\n",
    "\n",
    "canc_results = dict()\n",
    "\n",
    "\n",
    "# for different data sets\n",
    "for name, data in datasets.items():\n",
    "    X = data['X'].copy()\n",
    "    Y = data['Y'].copy()\n",
    "\n",
    "    print(name)\n",
    "\n",
    "    # different number of features\n",
    "    for n in [5, 10, 20]:\n",
    "        param['num_features'] = n\n",
    "\n",
    "        # different batch sizes -> batch size for one iteration, must be at least the same size than k!!\n",
    "        for b in [50, 100, 200]:        \n",
    "            param['batch_size'] = b\n",
    "\n",
    "            print(param)\n",
    "\n",
    "            w, stats = streamfs.simulate_stream(X, Y, 'nnfs', param)\n",
    "\n",
    "            canc_results[\"{};{}F;{}B\".format(name,n,b)] = {k: stats[k] for k in ['acc_avg', 'time_avg', 'memory_avg', 'fscr_avg', 'acc_measures', 'features', 'fscr_measures']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./experiment_results/canc_results.json', 'w') as fp:\n",
    "    json.dump(canc_results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load data from json\n",
    "with open('./experiment_results/canc_results.json', 'r') as fp:\n",
    "    data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
